{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pods\n",
    "\n",
    "from gp_ima.ima import C_ima_digamma, C_ima_sample\n",
    "import GPy\n",
    "from tueplots import bundles, figsizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.insert(0, '.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from analysis import plot_typography, estimate2uniform, generate_moebius_data, format_violin, RED, BLUE, calc_mcc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "USETEX = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams.update(bundles.neurips2022(usetex=USETEX))\n",
    "plt.rcParams.update({\n",
    "    'text.latex.preamble': [r'\\usepackage{amsfonts}', # mathbb\n",
    "                            r'\\usepackage{amsmath}'] # boldsymbol\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_typography(usetex=USETEX, small=12, medium=16, big=20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_bayesian_gplvm(X, dim, num_samples_c_ima, num_restarts, num_seeds, seed):\n",
    "    cimas_sparse = []\n",
    "    cimas_sparse_prior = []\n",
    "    zs_sparse = []\n",
    "    zs_uni_sparse = []\n",
    "    # np.random.seed(seed)\n",
    "    for i in range(num_seeds):\n",
    "        kernel = GPy.kern.RBF(dim, ARD=False) #+ GPy.kern.Bias(dim)\n",
    "        m = GPy.models.BayesianGPLVM(np.asarray(X), dim, kernel=kernel, num_inducing=20)\n",
    "        m.likelihood = GPy.likelihoods.Gaussian(variance=1e-6)\n",
    "        cimas_sparse_prior.append(C_ima_sample(m))\n",
    "        m.optimize_restarts(num_restarts, optimizer='lbfgs')\n",
    "\n",
    "        cimas_sparse.append(C_ima_sample(m))\n",
    "        zs_sparse.append(m.X.mean)\n",
    "        zs_uni_sparse.append(estimate2uniform(zs_sparse[-1]))\n",
    "\n",
    "    return cimas_sparse, cimas_sparse_prior, zs_sparse , zs_uni_sparse\n",
    "\n",
    "def train_gplvm(X, dim, num_samples_c_ima, num_restarts, num_seeds, seed):\n",
    "    cimas = []\n",
    "    cimas_prior = []\n",
    "    zs = []\n",
    "    zs_uni = []\n",
    "    # np.random.seed(seed)\n",
    "    for i in range(num_seeds):\n",
    "        kernel = GPy.kern.RBF(dim, ARD=False) #+ GPy.kern.Bias(dim)\n",
    "        m = GPy.models.GPLVM(np.asarray(X), dim, kernel=kernel)\n",
    "        m.likelihood = GPy.likelihoods.Gaussian(variance=1e-6)\n",
    "        cimas_prior.append(C_ima_sample(m))\n",
    "        m.optimize_restarts(num_restarts, optimizer='lbfgs')\n",
    "\n",
    "        cimas.append(C_ima_sample(m))\n",
    "        zs.append(m.X.values)\n",
    "        zs_uni.append(estimate2uniform(zs[-1]))\n",
    "\n",
    "    return cimas, cimas_prior, zs , zs_uni\n",
    "\n",
    "def calc_cima_prior_sample(dim, num_data, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    cimas_num_data = []\n",
    "    for n in num_data:\n",
    "        Z, X, c = generate_moebius_data(n, dim, dim)\n",
    "\n",
    "        kernel = GPy.kern.RBF(dim, ARD=False) + GPy.kern.Bias(dim)\n",
    "        m = GPy.models.GPLVM(np.asarray(X), dim, kernel=kernel)\n",
    "        m.likelihood = GPy.likelihoods.Gaussian(variance=1e-6)\n",
    "        cimas_num_data.append(C_ima_sample(m))\n",
    "    return cimas_num_data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MÃ¶bius transform"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_DATA = 500\n",
    "SEED = 42\n",
    "NUM_SEEDS = 5\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2D"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "NUM_SAMPLES_C_IMA = 100\n",
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = OBS_DIM = 2\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, cima = generate_moebius_data(NUM_DATA, LATENT_DIM, OBS_DIM)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "NUM_SAMPLES_C_IMA = 100\n",
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = OBS_DIM = 2\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, cima = generate_moebius_data(NUM_DATA, LATENT_DIM, OBS_DIM)\n",
    "\n",
    "cimas_sparse_2d, cimas_sparse_prior_2d, zs_sparse_2d, zs_uni_sparse_2d = train_bayesian_gplvm(X, DIM, NUM_SAMPLES_C_IMA,\n",
    "                                                                                              NUM_RESTARTS, NUM_SEEDS,\n",
    "                                                                                              SEED)\n",
    "mccs_sparse_2d = [calc_mcc(z, Z) for z in zs_uni_sparse_2d]\n",
    "\n",
    "NUM_RESTARTS = 2\n",
    "cimas_2d, cimas_prior_2d, zs_2d , zs_uni_2d = train_gplvm(X, DIM, NUM_SAMPLES_C_IMA, NUM_RESTARTS, NUM_SEEDS, SEED)\n",
    "mccs_2d = [calc_mcc(z, Z) for z in zs_uni_2d]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LABELPAD = 1\n",
    "TICK_PADDING = 2\n",
    "IDX = 0\n",
    "IDX_SPARSE = 0\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=1, ncols=2, rel_width=1)['figure.figsize'])\n",
    "\n",
    "ax = fig.add_subplot(131)\n",
    "ax.scatter(Z[:, 0], Z[:, 1], c=cima, cmap=\"hsv\", label=\"Latents\")\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.scatter(X[:, 0], X[:, 1], c=cima, cmap=\"hsv\", label=\"Observations\")\n",
    "\n",
    "# ax3 = fig.add_subplot(143)\n",
    "# ax3.scatter(zs_uni_2d[IDX][:, 0], zs_uni_2d[IDX][:, 1], c=c, cmap=\"hsv\", label=\"Rec. (GPLVM)\")\n",
    "\n",
    "\n",
    "ax4 = fig.add_subplot(133)\n",
    "ax4.scatter(zs_uni_sparse_2d[IDX_SPARSE][:, 0], zs_uni_sparse_2d[IDX_SPARSE][:, 1], c=cima, cmap=\"hsv\", label=\"Reconstruction\")\n",
    "\n",
    "\n",
    "# Remove ticks and labels and set which side to label\n",
    "ticksoff = dict(labelleft=False, labelright=False, left=False, right=False, labelbottom=False, bottom=False)\n",
    "ax.tick_params(axis=\"both\", **ticksoff)\n",
    "ax2.tick_params(axis=\"both\", **ticksoff)\n",
    "# ax3.tick_params(axis=\"both\", **ticksoff)\n",
    "ax4.tick_params(axis=\"both\", **ticksoff)\n",
    "\n",
    "ax.set_title(\"Latents\")\n",
    "ax2.set_title(\"Observations\")\n",
    "# ax3.set_title(\"Rec. (GPLVM)\")\n",
    "ax4.set_title(\"Reconstruction\")\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(\"gplvm_ima.svg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3D"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_SEEDS = 5\n",
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = OBS_DIM = 3\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, cima = generate_moebius_data(NUM_DATA, LATENT_DIM, OBS_DIM)\n",
    "\n",
    "# cimas_sparse_3d, cimas_sparse_prior_3d, zs_sparse_3d, zs_uni_sparse_3d = train_bayesian_gplvm(X, DIM, NUM_SAMPLES_C_IMA,\n",
    "#                                                                                               NUM_RESTARTS, NUM_SEEDS,\n",
    "#                                                                                               SEED)\n",
    "# mccs_sparse_3d = [calc_mcc(z, Z) for z in zs_uni_sparse_3d]\n",
    "\n",
    "NUM_RESTARTS = 2\n",
    "cimas_3d, cimas_prior_3d, zs_3d , zs_uni_3d = train_gplvm(X, DIM, NUM_SAMPLES_C_IMA, NUM_RESTARTS, NUM_SEEDS, SEED)\n",
    "mccs_3d = [calc_mcc(z, Z) for z in zs_uni_3d]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5D"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = OBS_DIM = 5\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, cima = generate_moebius_data(NUM_DATA, LATENT_DIM, OBS_DIM)\n",
    "\n",
    "# cimas_sparse_5d, cimas_sparse_prior_5d, zs_sparse_5d, zs_uni_sparse_5d = train_bayesian_gplvm(X, DIM, NUM_SAMPLES_C_IMA,\n",
    "#                                                                                               NUM_RESTARTS, NUM_SEEDS,\n",
    "#                                                                                               SEED)\n",
    "# mccs_sparse_5d = [calc_mcc(z, Z) for z in zs_uni_sparse_5d]\n",
    "\n",
    "NUM_RESTARTS = 2\n",
    "cimas_5d, cimas_prior_5d, zs_5d , zs_uni_5d = train_gplvm(X, DIM, NUM_SAMPLES_C_IMA, NUM_RESTARTS, NUM_SEEDS, SEED)\n",
    "mccs_5d = [calc_mcc(z, Z) for z in zs_uni_5d]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8D"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = OBS_DIM = 8\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, cima = generate_moebius_data(NUM_DATA, LATENT_DIM, OBS_DIM)\n",
    "\n",
    "# cimas_sparse_8d, cimas_sparse_prior_8d, zs_sparse_8d, zs_uni_sparse_8d = train_bayesian_gplvm(X, DIM, NUM_SAMPLES_C_IMA,\n",
    "#                                                                                               NUM_RESTARTS, NUM_SEEDS,\n",
    "#                                                                                               SEED)\n",
    "# mccs_sparse_8d = [calc_mcc(z, Z) for z in zs_uni_sparse_8d]\n",
    "\n",
    "NUM_RESTARTS = 2\n",
    "cimas_8d, cimas_prior_8d, zs_8d , zs_uni_8d = train_gplvm(X, DIM, NUM_SAMPLES_C_IMA, NUM_RESTARTS, NUM_SEEDS, SEED)\n",
    "mccs_8d = [calc_mcc(z, Z) for z in zs_uni_8d]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10D"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = OBS_DIM = 10\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, cima = generate_moebius_data(NUM_DATA, LATENT_DIM, OBS_DIM)\n",
    "\n",
    "# cimas_sparse_10d, cimas_sparse_prior_10d, zs_sparse_10d, zs_uni_sparse_10d = train_bayesian_gplvm(X, DIM,\n",
    "#                                                                                                   NUM_SAMPLES_C_IMA,\n",
    "#                                                                                                   NUM_RESTARTS,\n",
    "#                                                                                                   NUM_SEEDS, SEED)\n",
    "# mccs_sparse_10d = [calc_mcc(z, Z) for z in zs_uni_sparse_10d]\n",
    "\n",
    "NUM_RESTARTS = 2\n",
    "cimas_10d, cimas_prior_10d, zs_10d , zs_uni_10d = train_gplvm(X, DIM, NUM_SAMPLES_C_IMA, NUM_RESTARTS, NUM_SEEDS, SEED)\n",
    "mccs_10d = [calc_mcc(z, Z) for z in zs_uni_10d]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = OBS_DIM = 12\n",
    "NUM_DATA = 500\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, cima = generate_moebius_data(NUM_DATA, LATENT_DIM, OBS_DIM)\n",
    "\n",
    "# cimas_sparse_10d, cimas_sparse_prior_10d, zs_sparse_10d, zs_uni_sparse_10d = train_bayesian_gplvm(X, DIM,\n",
    "#                                                                                                   NUM_SAMPLES_C_IMA,\n",
    "#                                                                                                   NUM_RESTARTS,\n",
    "#                                                                                                   NUM_SEEDS, SEED)\n",
    "# mccs_sparse_10d = [calc_mcc(z, Z) for z in zs_uni_sparse_10d]\n",
    "\n",
    "NUM_RESTARTS = 2\n",
    "cimas_12d, cimas_prior_12d, zs_12d , zs_uni_12d = train_gplvm(X, DIM, NUM_SAMPLES_C_IMA, NUM_RESTARTS, 2, SEED)\n",
    "mccs_12d = [calc_mcc(z, Z) for z in zs_uni_12d]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    cimas = [cimas_2d, cimas_3d, cimas_5d, cimas_8d, cimas_10d]\n",
    "    cimas_prior = [cimas_prior_2d, cimas_prior_3d, cimas_prior_5d, cimas_prior_8d, cimas_prior_10d]\n",
    "\n",
    "    np.savez(\"cimas.npz\", cimas=cimas, cimas_prior=cimas_prior)\n",
    "except:\n",
    "    cimas = np.load(\"cimas.npz\", allow_pickle=True)['cimas']\n",
    "    cimas_prior = np.load(\"cimas.npz\", allow_pickle=True)['cimas_prior']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    mccs = [mccs_2d, mccs_3d, mccs_5d, mccs_8d, mccs_10d]\n",
    "    np.savez(\"mccs.npz\", mccs=mccs)\n",
    "except:\n",
    "    mccs = np.load(\"mccs.npz\", allow_pickle=True)['mccs']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot MCC and CIMA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LABELPAD = 2\n",
    "TICK_PADDING = 0\n",
    "dimensions = np.array([2,3,5,8,10])\n",
    "\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=2, ncols=3)['figure.figsize'])\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "\n",
    "\n",
    "ax.scatter(dimensions,[np.log10(g).mean() for g in cimas_prior], c=BLUE, label=\"Prior\")\n",
    "ax.scatter(dimensions,[np.log10(g).mean() for g in cimas], c=RED, label=\"Posterior\")\n",
    "\n",
    "Ds = np.linspace(1, 10, 10).astype(int)\n",
    "lp = ax.plot(Ds, [np.log10(C_ima_digamma(D, D)) for D in Ds], label=\"Bound\", c=\"black\")\n",
    "\n",
    "ax.set_ylabel(\"$\\log_{10}c_{\\mathrm{IMA}}$\", labelpad=LABELPAD)\n",
    "ax.set_xlabel(\"$d=D$\", labelpad=LABELPAD)\n",
    "ax.set_xticks(dimensions.tolist())\n",
    "ax.set_xticklabels(dimensions.tolist())\n",
    "plt.legend( loc='center right')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax2.grid(True, which=\"both\", ls=\"-.\")\n",
    "\n",
    "ax2.scatter(dimensions, np.array(mccs).mean(1), c=RED, label=\"MCC\")\n",
    "\n",
    "\n",
    "ax2.set_ylabel(\"$\\mathrm{MCC}$\", labelpad=LABELPAD)\n",
    "ax2.set_xlabel(\"$d=D$\", labelpad=LABELPAD)\n",
    "\n",
    "ax2.set_xticks(dimensions.tolist())\n",
    "ax2.set_xticklabels(dimensions.tolist())\n",
    "\n",
    "plt.legend(loc='center right')\n",
    "\n",
    "plt.savefig(\"cima_mcc.svg\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data-dependence of prior CIMA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_data = [50, 100, 200, 500, 1000, 2000]\n",
    "DIM = LATENT_DIM = OBS_DIM = 2\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cimas_num_data2d = calc_cima_prior_sample(2, num_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cimas_num_data3d = calc_cima_prior_sample(3, num_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cimas_num_data5d = calc_cima_prior_sample(5, num_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cimas_num_data8d = calc_cima_prior_sample(8, num_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cimas_num_data10d = calc_cima_prior_sample(10, num_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    cimas_num_data2d = np.load(\"cimas_num_data.npz\")['cimas_num_data2d']\n",
    "    cimas_num_data3d = np.load(\"cimas_num_data.npz\")['cimas_num_data3d']\n",
    "    cimas_num_data5d = np.load(\"cimas_num_data.npz\")['cimas_num_data5d']\n",
    "    cimas_num_data8d = np.load(\"cimas_num_data.npz\")['cimas_num_data8d']\n",
    "    cimas_num_data10d = np.load(\"cimas_num_data.npz\")['cimas_num_data10d']\n",
    "    cimas_num_data = [cimas_num_data2d, cimas_num_data3d, cimas_num_data5d, cimas_num_data8d, cimas_num_data10d]\n",
    "except:\n",
    "    cimas_num_data2d = calc_cima_prior_sample(2, num_data)\n",
    "    cimas_num_data3d = calc_cima_prior_sample(3, num_data)\n",
    "    cimas_num_data5d = calc_cima_prior_sample(5, num_data)\n",
    "    cimas_num_data8d = calc_cima_prior_sample(8, num_data)\n",
    "    cimas_num_data10d = calc_cima_prior_sample(10, num_data)\n",
    "    np.savez(\"cimas_num_data.npz\", cimas_num_data2d=cimas_num_data2d, cimas_num_data3d=cimas_num_data3d, cimas_num_data5d=cimas_num_data5d, cimas_num_data8d=cimas_num_data8d, cimas_num_data10d=cimas_num_data10d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LABELPAD = 2\n",
    "TICK_PADDING = 0\n",
    "dimensions = np.array([2,3,5,8,10])\n",
    "cimas_num_data = [cimas_num_data2d, cimas_num_data3d, cimas_num_data5d, cimas_num_data8d, cimas_num_data10d]\n",
    "\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=1, ncols=1)['figure.figsize'])\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "\n",
    "markers = [\"o\", \"s\", \"D\", \"X\", \"P\"]\n",
    "colors = [\"blue\", \"orange\", \"green\", \"red\", \"purple\"]\n",
    "\n",
    "for d,c, cima in zip(dimensions, colors, cimas_num_data):\n",
    "    for m, cima_per_num_data in zip(markers,cima):\n",
    "        ax.scatter(d, np.log10(cima_per_num_data), marker=m, c=c, s=20)\n",
    "\n",
    "\n",
    "\n",
    "Ds = np.linspace(1, 10, 10).astype(int)\n",
    "lp = ax.plot(Ds, [np.log10(C_ima_digamma(D, D)) for D in Ds], label=\"Bound\", c=\"black\")\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"$\\log_{10}c_{\\mathrm{IMA}}$\", labelpad=LABELPAD)\n",
    "ax.set_xlabel(\"$d=D$\", labelpad=LABELPAD)\n",
    "ax.set_xticks(dimensions)\n",
    "ax.set_xticklabels(dimensions)\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "legend_elements = [mlines.Line2D([0], [0], marker=m, color='w', label=f\"${n}$\",\n",
    "                          markerfacecolor='black', markersize=10) for n,m in zip(num_data, markers)\n",
    "                   ]\n",
    "legend_elements += [mlines.Line2D([], [], color='black', linestyle='solid', label=f\"Bound\",\n",
    "                          markersize=10)]\n",
    "\n",
    "legend_marker =  ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# add legend describing the colors\n",
    "legend_elements = [mlines.Line2D([0], [0], marker='o', color='w', label=f\"{d}\",\n",
    "                          markerfacecolor=c, markersize=10) for d,c in zip(dimensions, colors)\n",
    "                   ]\n",
    "\n",
    "legend_dim= ax.legend(handles=legend_elements, loc='lower center', ncol=len(dimensions), handlelength=0.5, columnspacing=0.5)\n",
    "\n",
    "\n",
    "ax.add_artist(legend_dim)\n",
    "ax.add_artist(legend_marker)\n",
    "\n",
    "\n",
    "plt.savefig(\"cima_num_data.svg\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

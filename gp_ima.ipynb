{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pods\n",
    "\n",
    "from gp_ima.ima import C_ima_digamma, C_ima_sample\n",
    "import GPy\n",
    "from tueplots import bundles, figsizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.insert(0, '.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from analysis import plot_typography, estimate2uniform, generate_moebius_data, format_violin, RED, BLUE, calc_mcc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "USETEX = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams.update(bundles.neurips2022(usetex=USETEX))\n",
    "plt.rcParams.update({\n",
    "    'text.latex.preamble': [r'\\usepackage{amsfonts}', # mathbb\n",
    "                            r'\\usepackage{amsmath}'] # boldsymbol\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_typography(usetex=USETEX, small=12, medium=16, big=20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_bayesian_gplvm(X, dim, num_samples_c_ima, num_restarts, num_seeds, seed):\n",
    "    cimas_sparse = []\n",
    "    cimas_sparse_prior = []\n",
    "    zs_sparse = []\n",
    "    zs_uni_sparse = []\n",
    "    # np.random.seed(seed)\n",
    "    for i in range(num_seeds):\n",
    "        kernel = GPy.kern.RBF(dim, ARD=False) #+ GPy.kern.Bias(dim)\n",
    "        m = GPy.models.BayesianGPLVM(np.asarray(X), dim, kernel=kernel, num_inducing=20)\n",
    "        m.likelihood = GPy.likelihoods.Gaussian(variance=1e-6)\n",
    "        cimas_sparse_prior.append(C_ima_sample(m))\n",
    "        m.optimize_restarts(num_restarts, optimizer='lbfgs')\n",
    "\n",
    "        cimas_sparse.append(C_ima_sample(m))\n",
    "        zs_sparse.append(m.X.mean)\n",
    "        zs_uni_sparse.append(estimate2uniform(zs_sparse[-1]))\n",
    "\n",
    "    return cimas_sparse, cimas_sparse_prior, zs_sparse , zs_uni_sparse\n",
    "\n",
    "def train_gplvm(X, dim, num_samples_c_ima, num_restarts, num_seeds, seed):\n",
    "    cimas = []\n",
    "    cimas_prior = []\n",
    "    zs = []\n",
    "    zs_uni = []\n",
    "    # np.random.seed(seed)\n",
    "    for i in range(num_seeds):\n",
    "        kernel = GPy.kern.RBF(dim, ARD=False) #+ GPy.kern.Bias(dim)\n",
    "        m = GPy.models.GPLVM(np.asarray(X), dim, kernel=kernel)\n",
    "        m.likelihood = GPy.likelihoods.Gaussian(variance=1e-6)\n",
    "        cimas_prior.append(C_ima_sample(m))\n",
    "        m.optimize_restarts(num_restarts, optimizer='lbfgs')\n",
    "\n",
    "        cimas.append(C_ima_sample(m))\n",
    "        zs.append(m.X.values)\n",
    "        zs_uni.append(estimate2uniform(zs[-1]))\n",
    "\n",
    "    return cimas, cimas_prior, zs , zs_uni\n",
    "\n",
    "def calc_cima_prior_sample(dim, num_data, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    cimas_num_data = []\n",
    "    for n in num_data:\n",
    "        Z, X, c = generate_moebius_data(n, dim, dim)\n",
    "\n",
    "        kernel = GPy.kern.RBF(dim, ARD=False) #+ GPy.kern.Bias(dim)\n",
    "        m = GPy.models.GPLVM(np.asarray(X), dim, kernel=kernel)\n",
    "        m.likelihood = GPy.likelihoods.Gaussian(variance=1e-6)\n",
    "        cimas_num_data.append(C_ima_sample(m))\n",
    "    return cimas_num_data\n",
    "\n",
    "def train_oil_gplvm(latent_dim, num_samples_c_ima=100, plot=True):\n",
    "    data = pods.datasets.oil_100()\n",
    "    Y = data[\"X\"]\n",
    "\n",
    "    kernel = GPy.kern.RBF(latent_dim, ARD=False) + GPy.kern.Bias(latent_dim)\n",
    "    oil_gplvm = GPy.models.GPLVM(Y, latent_dim, kernel=kernel)\n",
    "    oil_gplvm.likelihood = GPy.likelihoods.Gaussian(variance=1e-6)\n",
    "    oil_gplvm.data_labels = data[\"Y\"].argmax(axis=1)\n",
    "    cima_oil_prior = C_ima_sample(oil_gplvm)\n",
    "    oil_gplvm.optimize(\"scg\", messages=0)\n",
    "    if plot:\n",
    "        oil_gplvm.plot_latent(labels=oil_gplvm.data_labels)\n",
    "\n",
    "    cima_oil =  C_ima_sample(oil_gplvm)\n",
    "\n",
    "    return oil_gplvm, cima_oil_prior, cima_oil\n",
    "\n",
    "def stick(latent_dim, optimize=True, verbose=False, plot=True, num_samples_c_ima=NUM_SAMPLES_C_IMA, variance=1e-6):\n",
    "    from matplotlib import pyplot as plt\n",
    "    import GPy\n",
    "    import pods\n",
    "\n",
    "    data = pods.datasets.osu_run1()\n",
    "    kernel = GPy.kern.RBF(latent_dim, ARD=True) + GPy.kern.Bias(latent_dim)\n",
    "\n",
    "    # optimize\n",
    "    m = GPy.models.GPLVM(data[\"Y\"], latent_dim, kernel=kernel)\n",
    "    m.likelihood = GPy.likelihoods.Gaussian(variance=variance)\n",
    "    cima_stick_prior =  C_ima_sample(m)\n",
    "    if optimize:\n",
    "        m.optimize(\"bfgs\", messages=verbose, max_f_eval=15000)\n",
    "    cima_stick =  C_ima_sample(m)\n",
    "    if plot:\n",
    "        plt.clf\n",
    "        ax = m.plot_latent()\n",
    "    return m, cima_stick_prior, cima_stick\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_DATA = 500\n",
    "SEED = 42\n",
    "NUM_SEEDS = 5\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2D"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "NUM_SAMPLES_C_IMA = 100\n",
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = OBS_DIM = 2\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, c = generate_moebius_data(NUM_DATA, LATENT_DIM, OBS_DIM)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "NUM_SAMPLES_C_IMA = 100\n",
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = OBS_DIM = 2\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, c = generate_moebius_data(NUM_DATA, LATENT_DIM, OBS_DIM)\n",
    "\n",
    "cimas_sparse_2d, cimas_sparse_prior_2d, zs_sparse_2d, zs_uni_sparse_2d = train_bayesian_gplvm(X, DIM, NUM_SAMPLES_C_IMA,\n",
    "                                                                                              NUM_RESTARTS, NUM_SEEDS,\n",
    "                                                                                              SEED)\n",
    "mccs_sparse_2d = [calc_mcc(z, Z) for z in zs_uni_sparse_2d]\n",
    "\n",
    "NUM_RESTARTS = 2\n",
    "cimas_2d, cimas_prior_2d, zs_2d , zs_uni_2d = train_gplvm(X, DIM, NUM_SAMPLES_C_IMA, NUM_RESTARTS, NUM_SEEDS, SEED)\n",
    "mccs_2d = [calc_mcc(z, Z) for z in zs_uni_2d]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LABELPAD = 1\n",
    "TICK_PADDING = 2\n",
    "IDX = 0\n",
    "IDX_SPARSE = 0\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=1, ncols=2, rel_width=1)['figure.figsize'])\n",
    "\n",
    "ax = fig.add_subplot(131)\n",
    "ax.scatter(Z[:, 0], Z[:, 1], c=c, cmap=\"hsv\", label=\"Latents\")\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.scatter(X[:, 0], X[:, 1], c=c, cmap=\"hsv\", label=\"Observations\")\n",
    "\n",
    "# ax3 = fig.add_subplot(143)\n",
    "# ax3.scatter(zs_uni_2d[IDX][:, 0], zs_uni_2d[IDX][:, 1], c=c, cmap=\"hsv\", label=\"Rec. (GPLVM)\")\n",
    "\n",
    "\n",
    "ax4 = fig.add_subplot(133)\n",
    "ax4.scatter(zs_uni_sparse_2d[IDX_SPARSE][:, 0], zs_uni_sparse_2d[IDX_SPARSE][:, 1], c=c, cmap=\"hsv\", label=\"Reconstruction\")\n",
    "\n",
    "\n",
    "# Remove ticks and labels and set which side to label\n",
    "ticksoff = dict(labelleft=False, labelright=False, left=False, right=False, labelbottom=False, bottom=False)\n",
    "ax.tick_params(axis=\"both\", **ticksoff)\n",
    "ax2.tick_params(axis=\"both\", **ticksoff)\n",
    "# ax3.tick_params(axis=\"both\", **ticksoff)\n",
    "ax4.tick_params(axis=\"both\", **ticksoff)\n",
    "\n",
    "ax.set_title(\"Latents\")\n",
    "ax2.set_title(\"Observations\")\n",
    "# ax3.set_title(\"Rec. (GPLVM)\")\n",
    "ax4.set_title(\"Reconstruction\")\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(\"gplvm_ima.svg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3D"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_SEEDS = 5\n",
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = OBS_DIM = 3\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, c = generate_moebius_data(NUM_DATA, LATENT_DIM, OBS_DIM)\n",
    "\n",
    "# cimas_sparse_3d, cimas_sparse_prior_3d, zs_sparse_3d, zs_uni_sparse_3d = train_bayesian_gplvm(X, DIM, NUM_SAMPLES_C_IMA,\n",
    "#                                                                                               NUM_RESTARTS, NUM_SEEDS,\n",
    "#                                                                                               SEED)\n",
    "# mccs_sparse_3d = [calc_mcc(z, Z) for z in zs_uni_sparse_3d]\n",
    "\n",
    "NUM_RESTARTS = 2\n",
    "cimas_3d, cimas_prior_3d, zs_3d , zs_uni_3d = train_gplvm(X, DIM, NUM_SAMPLES_C_IMA, NUM_RESTARTS, NUM_SEEDS, SEED)\n",
    "mccs_3d = [calc_mcc(z, Z) for z in zs_uni_3d]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5D"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = OBS_DIM = 5\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, c = generate_moebius_data(NUM_DATA, LATENT_DIM, OBS_DIM)\n",
    "\n",
    "# cimas_sparse_5d, cimas_sparse_prior_5d, zs_sparse_5d, zs_uni_sparse_5d = train_bayesian_gplvm(X, DIM, NUM_SAMPLES_C_IMA,\n",
    "#                                                                                               NUM_RESTARTS, NUM_SEEDS,\n",
    "#                                                                                               SEED)\n",
    "# mccs_sparse_5d = [calc_mcc(z, Z) for z in zs_uni_sparse_5d]\n",
    "\n",
    "NUM_RESTARTS = 2\n",
    "cimas_5d, cimas_prior_5d, zs_5d , zs_uni_5d = train_gplvm(X, DIM, NUM_SAMPLES_C_IMA, NUM_RESTARTS, NUM_SEEDS, SEED)\n",
    "mccs_5d = [calc_mcc(z, Z) for z in zs_uni_5d]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8D"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = OBS_DIM = 8\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, c = generate_moebius_data(NUM_DATA, LATENT_DIM, OBS_DIM)\n",
    "\n",
    "# cimas_sparse_8d, cimas_sparse_prior_8d, zs_sparse_8d, zs_uni_sparse_8d = train_bayesian_gplvm(X, DIM, NUM_SAMPLES_C_IMA,\n",
    "#                                                                                               NUM_RESTARTS, NUM_SEEDS,\n",
    "#                                                                                               SEED)\n",
    "# mccs_sparse_8d = [calc_mcc(z, Z) for z in zs_uni_sparse_8d]\n",
    "\n",
    "NUM_RESTARTS = 2\n",
    "cimas_8d, cimas_prior_8d, zs_8d , zs_uni_8d = train_gplvm(X, DIM, NUM_SAMPLES_C_IMA, NUM_RESTARTS, NUM_SEEDS, SEED)\n",
    "mccs_8d = [calc_mcc(z, Z) for z in zs_uni_8d]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10D"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = OBS_DIM = 10\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, c = generate_moebius_data(NUM_DATA, LATENT_DIM, OBS_DIM)\n",
    "\n",
    "# cimas_sparse_10d, cimas_sparse_prior_10d, zs_sparse_10d, zs_uni_sparse_10d = train_bayesian_gplvm(X, DIM,\n",
    "#                                                                                                   NUM_SAMPLES_C_IMA,\n",
    "#                                                                                                   NUM_RESTARTS,\n",
    "#                                                                                                   NUM_SEEDS, SEED)\n",
    "# mccs_sparse_10d = [calc_mcc(z, Z) for z in zs_uni_sparse_10d]\n",
    "\n",
    "NUM_RESTARTS = 2\n",
    "cimas_10d, cimas_prior_10d, zs_10d , zs_uni_10d = train_gplvm(X, DIM, NUM_SAMPLES_C_IMA, NUM_RESTARTS, NUM_SEEDS, SEED)\n",
    "mccs_10d = [calc_mcc(z, Z) for z in zs_uni_10d]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = OBS_DIM = 12\n",
    "NUM_DATA = 500\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, c = generate_moebius_data(NUM_DATA, LATENT_DIM, OBS_DIM)\n",
    "\n",
    "# cimas_sparse_10d, cimas_sparse_prior_10d, zs_sparse_10d, zs_uni_sparse_10d = train_bayesian_gplvm(X, DIM,\n",
    "#                                                                                                   NUM_SAMPLES_C_IMA,\n",
    "#                                                                                                   NUM_RESTARTS,\n",
    "#                                                                                                   NUM_SEEDS, SEED)\n",
    "# mccs_sparse_10d = [calc_mcc(z, Z) for z in zs_uni_sparse_10d]\n",
    "\n",
    "NUM_RESTARTS = 2\n",
    "cimas_12d, cimas_prior_12d, zs_12d , zs_uni_12d = train_gplvm(X, DIM, NUM_SAMPLES_C_IMA, NUM_RESTARTS, 2, SEED)\n",
    "mccs_12d = [calc_mcc(z, Z) for z in zs_uni_12d]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    cimas = [cimas_2d, cimas_3d, cimas_5d, cimas_8d, cimas_10d]\n",
    "    cimas_prior = [cimas_prior_2d, cimas_prior_3d, cimas_prior_5d, cimas_prior_8d, cimas_prior_10d]\n",
    "\n",
    "    np.savez(\"cimas.npz\", cimas=cimas, cimas_prior=cimas_prior)\n",
    "except:\n",
    "    cimas = np.load(\"cimas.npz\", allow_pickle=True)['cimas']\n",
    "    cimas_prior = np.load(\"cimas.npz\", allow_pickle=True)['cimas_prior']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    mccs = [mccs_2d, mccs_3d, mccs_5d, mccs_8d, mccs_10d]\n",
    "    np.savez(\"mccs.npz\", mccs=mccs)\n",
    "except:\n",
    "    mccs = np.load(\"mccs.npz\", allow_pickle=True)['mccs']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot MCC and CIMA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LABELPAD = 2\n",
    "TICK_PADDING = 0\n",
    "dimensions = np.array([2,3,5,8,10])\n",
    "\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=2, ncols=3)['figure.figsize'])\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "\n",
    "\n",
    "ax.scatter(dimensions,[np.log10(g).mean() for g in cimas_prior], c=BLUE, label=\"Prior\")\n",
    "ax.scatter(dimensions,[np.log10(g).mean() for g in cimas], c=RED, label=\"Posterior\")\n",
    "\n",
    "Ds = np.linspace(1, 10, 10).astype(int)\n",
    "lp = ax.plot(Ds, [np.log10(C_ima_digamma(D, D)) for D in Ds], label=\"Bound\", c=\"black\")\n",
    "\n",
    "ax.set_ylabel(\"$\\log_{10}c_{\\mathrm{IMA}}$\", labelpad=LABELPAD)\n",
    "ax.set_xlabel(\"$d=D$\", labelpad=LABELPAD)\n",
    "ax.set_xticks(dimensions.tolist())\n",
    "ax.set_xticklabels(dimensions.tolist())\n",
    "plt.legend( loc='center right')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax2.grid(True, which=\"both\", ls=\"-.\")\n",
    "\n",
    "ax2.scatter(dimensions, np.array(mccs).mean(1), c=RED, label=\"MCC\")\n",
    "\n",
    "\n",
    "ax2.set_ylabel(\"$\\mathrm{MCC}$\", labelpad=LABELPAD)\n",
    "ax2.set_xlabel(\"$d=D$\", labelpad=LABELPAD)\n",
    "\n",
    "ax2.set_xticks(dimensions.tolist())\n",
    "ax2.set_xticklabels(dimensions.tolist())\n",
    "\n",
    "plt.legend(loc='center right')\n",
    "\n",
    "plt.savefig(\"cima_mcc.svg\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Oil 100 dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oil_gplvm_2d, cima_oil_prior_2d, cima_oil_2d = train_oil_gplvm(2, plot=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oil_gplvm_3d, cima_oil_prior_3d, cima_oil_3d = train_oil_gplvm(3, plot=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oil_gplvm_4d, cima_oil_prior_4d, cima_oil_4d = train_oil_gplvm(4, plot=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oil_gplvm_5d, cima_oil_prior_5d, cima_oil_5d = train_oil_gplvm(5, plot=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oil_gplvm_6d, cima_oil_prior_6d, cima_oil_6d = train_oil_gplvm(6, plot=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LABELPAD = 2\n",
    "TICK_PADDING = 0\n",
    "cimas_oil = [cima_oil_2d, cima_oil_3d, cima_oil_4d, cima_oil_5d, cima_oil_6d]\n",
    "cimas_oil_prior = [cima_oil_prior_2d, cima_oil_prior_3d, cima_oil_prior_4d, cima_oil_prior_5d,cima_oil_prior_6d]\n",
    "dimensions = np.array([2,3,4,5,6])\n",
    "\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=1, ncols=1)['figure.figsize'])\n",
    "\n",
    "\n",
    "\"\"\"MCC vs CIMA over different gamma\"\"\"\n",
    "ax = fig.add_subplot(111)\n",
    "ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "\n",
    "\n",
    "# MCC\n",
    "ax.scatter(dimensions.tolist(),[np.log10(g).mean() for g in cimas_oil_prior], c=BLUE, label=\"Prior\")\n",
    "ax.scatter(dimensions,[np.log10(g).mean() for g in cimas_oil], c=RED, label=\"Posterior\")\n",
    "\n",
    "lp = ax.plot(dimensions, [np.log10(C_ima_digamma(d, 12)) for d in dimensions], label=\"Bound\", c=\"black\")\n",
    "\n",
    "ax.set_ylabel(\"$\\log_{10}c_{\\mathrm{IMA}}$\", labelpad=LABELPAD)\n",
    "ax.set_xlabel(\"$d$\", labelpad=LABELPAD)\n",
    "ax.set_xticks(dimensions.tolist())\n",
    "ax.set_xticklabels(dimensions.tolist())\n",
    "plt.legend( loc='lower right')\n",
    "\n",
    "\n",
    "plt.savefig(\"cima_oil.svg\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stick dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stick_2d, cima_stick_prior_2d, cima_stick_2d = stick(2)\n",
    "cima_stick_prior_2d, cima_stick_2d, C_ima_digamma(2, 102)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stick_3d, cima_stick_prior_3d, cima_stick_3d = stick(3, variance=7e-5)\n",
    "cima_stick_prior_3d, cima_stick_3d, C_ima_digamma(3, 102)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stick_4d, cima_stick_prior_4d, cima_stick_4d = stick(4)\n",
    "cima_stick_prior_4d, cima_stick_4d, C_ima_digamma(4, 102)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stick_6d, cima_stick_prior_6d, cima_stick_6d = stick(6)\n",
    "cima_stick_prior_6d, cima_stick_6d, C_ima_digamma(6, 102)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stick_10d, cima_stick_prior_10d, cima_stick_10d = stick(10)\n",
    "cima_stick_10d, cima_stick_prior_10d, C_ima_digamma(10, 102)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stick_20d, cima_stick_prior_20d, cima_stick_20d = stick(20)\n",
    "cima_stick_20d, cima_stick_prior_20d, C_ima_digamma(20, 102)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stick_40d, cima_stick_prior_40d, cima_stick_40d = stick(40)\n",
    "cima_stick_40d, cima_stick_prior_40d, C_ima_digamma(40, 102)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stick_60d, cima_stick_prior_60d, cima_stick_60d = stick(60)\n",
    "cima_stick_60d, cima_stick_prior_60d, C_ima_digamma(60, 102)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LABELPAD = 2\n",
    "TICK_PADDING = 0\n",
    "cimas_stick = [cima_stick_2d, cima_stick_3d, cima_stick_4d, cima_stick_6d, cima_stick_10d, cima_stick_20d, cima_stick_40d]\n",
    "cimas_stick_prior = [cima_stick_prior_2d, cima_stick_prior_3d, cima_stick_prior_4d, cima_stick_prior_6d, cima_stick_prior_10d, cima_stick_prior_20d, cima_stick_prior_40d]\n",
    "dimensions = np.array([2,3,4,6,10, 20, 40])\n",
    "\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=1, ncols=1)['figure.figsize'])\n",
    "\n",
    "\n",
    "\"\"\"MCC vs CIMA over different gamma\"\"\"\n",
    "ax = fig.add_subplot(111)\n",
    "ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "\n",
    "\n",
    "# MCC\n",
    "ax.scatter(dimensions.tolist(),[np.log10(g).mean() for g in cimas_stick_prior], c=BLUE, label=\"Prior\")\n",
    "ax.scatter(dimensions,[np.log10(g).mean() for g in cimas_stick], c=RED, label=\"Posterior\")\n",
    "\n",
    "lp = ax.plot(dimensions, [np.log10(C_ima_digamma(d, 102)) for d in dimensions], label=\"Bound\", c=\"black\")\n",
    "\n",
    "ax.set_ylabel(\"$\\log_{10}c_{\\mathrm{IMA}}$\", labelpad=LABELPAD)\n",
    "ax.set_xlabel(\"$d$\", labelpad=LABELPAD)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(dimensions.tolist())\n",
    "ax.set_xticklabels(dimensions.tolist())\n",
    "\n",
    "\n",
    "plt.legend( loc='lower right')\n",
    "\n",
    "\n",
    "plt.savefig(\"cima_stick.svg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Synthetic high-dimensional observations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_SEEDS = 5\n",
    "NUM_RESTARTS = 5\n",
    "DIM = LATENT_DIM = 3\n",
    "OBS_DIM = 8\n",
    "NUM_DATA_A = 2500\n",
    "\n",
    "np.random.seed(SEED)\n",
    "Z, X, c = generate_moebius_data(NUM_DATA_A, LATENT_DIM, LATENT_DIM)\n",
    "\n",
    "A= np.random.randn(OBS_DIM, LATENT_DIM)\n",
    "\n",
    "XA = X@A.T\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_RESTARTS = 2\n",
    "cimas_A, cimas_prior_A, zs_A , zs_uni_A = train_gplvm(XA, LATENT_DIM, NUM_SAMPLES_C_IMA, NUM_RESTARTS, 1, SEED)\n",
    "mccs_A = [calc_mcc(z, Z) for z in zs_uni_A]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cimas_A, cimas_prior_A, C_ima_digamma(LATENT_DIM, OBS_DIM)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LATENT_DIM = 5\n",
    "np.random.seed(SEED)\n",
    "Z, X, c = generate_moebius_data(500, LATENT_DIM, LATENT_DIM)\n",
    "kernel = GPy.kern.RBF(LATENT_DIM, ARD=False) #+ GPy.kern.Bias(dim)\n",
    "m = GPy.models.GPLVM(np.asarray(XA), LATENT_DIM, kernel=kernel)\n",
    "m.likelihood = GPy.likelihoods.Gaussian(variance=1e-6)\n",
    "C_ima_sample(m)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data-dependence of prior CIMA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_data = [50, 100, 200, 500, 10000]\n",
    "DIM = LATENT_DIM = OBS_DIM = 2\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cimas_num_data2d = calc_cima_prior_sample(2, num_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cimas_num_data3d = calc_cima_prior_sample(3, num_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cimas_num_data5d = calc_cima_prior_sample(5, num_data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cimas_num_data8d = calc_cima_prior_sample(8, num_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cimas_num_data10d = calc_cima_prior_sample(10, num_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    cimas_num_data2d = np.load(\"cimas_num_data.npz\")['cimas_num_data2d']\n",
    "    cimas_num_data3d = np.load(\"cimas_num_data.npz\")['cimas_num_data3d']\n",
    "    cimas_num_data5d = np.load(\"cimas_num_data.npz\")['cimas_num_data5d']\n",
    "    cimas_num_data8d = np.load(\"cimas_num_data.npz\")['cimas_num_data8d']\n",
    "    cimas_num_data10d = np.load(\"cimas_num_data.npz\")['cimas_num_data10d']\n",
    "    cimas_num_data = [cimas_num_data2d, cimas_num_data3d, cimas_num_data5d, cimas_num_data8d, cimas_num_data10d]\n",
    "except:\n",
    "    cimas_num_data2d = calc_cima_prior_sample(2, num_data)\n",
    "    cimas_num_data3d = calc_cima_prior_sample(3, num_data)\n",
    "    cimas_num_data5d = calc_cima_prior_sample(5, num_data)\n",
    "    cimas_num_data8d = calc_cima_prior_sample(8, num_data)\n",
    "    cimas_num_data10d = calc_cima_prior_sample(10, num_data)\n",
    "    np.savez(\"cimas_num_data.npz\", cimas_num_data2d=cimas_num_data2d, cimas_num_data3d=cimas_num_data3d, cimas_num_data5d=cimas_num_data5d, cimas_num_data8d=cimas_num_data8d, cimas_num_data10d=cimas_num_data10d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LABELPAD = 2\n",
    "TICK_PADDING = 0\n",
    "dimensions = np.array([2,3,5,8,10])\n",
    "cimas_num_data = [cimas_num_data2d, cimas_num_data3d, cimas_num_data5d, cimas_num_data8d, cimas_num_data10d]\n",
    "\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=2, ncols=3)['figure.figsize'])\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "\n",
    "for d,c in zip(dimensions, cimas_num_data):\n",
    "    ax.scatter(d*np.ones_like(c),[np.log10(g) for g in c], label=f\"{d}D\")\n",
    "\n",
    "\n",
    "\n",
    "Ds = np.linspace(1, 10, 10).astype(int)\n",
    "lp = ax.plot(Ds, [np.log10(C_ima_digamma(D, D)) for D in Ds], label=\"Bound\", c=\"black\")\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"$\\log_{10}c_{\\mathrm{IMA}}$\", labelpad=LABELPAD)\n",
    "ax.set_xlabel(\"$d=D$\", labelpad=LABELPAD)\n",
    "ax.set_xticks(dimensions)\n",
    "ax.set_xticklabels(dimensions)\n",
    "plt.legend( loc='center right')\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(\"cima_num_data.svg\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
